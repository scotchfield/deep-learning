# Chapter 1: Introduction

**Deep learning**: Allowing computers to learn from experience and understand the world in terms of a hierarchy of concepts, with each concept defined through its relation to simpler concepts. By gathering knowledge from experience, this approach avoids the need for human operators to formally specify all the knowledge that the computer needs. The hierarchy of concepts enables the computer to learn complicated concepts by building them out of simpler ones. If we draw a graph showing how these concepts are built on top of each other, the graph is deep, with many layers.

**Representation learning**: Using machine learning to discover not only the mapping from representation to output but also the representation itself.

**Autoencoder**: The combination of an encoder function, which converts the input data into a different representation, and a decoder function, which converts the new representation back into the original format.

**Multiplayer Perceptron (MLP)**: Also known as the feedforward deep network. A multilayer perceptron is just a mathematical function mapping some set of input values to output values. The function is formed by composing many simpler functions. We can think of each application of a different mathematical function as providing a new representation of the input.

**Reinforcement learning**: When an autonomous agent must learn to perform a task by trial and error, without any guidance from the human operator.
